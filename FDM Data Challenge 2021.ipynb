{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "solved-satellite",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import unix_timestamp, monotonically_increasing_id, col\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from datetime import datetime\n",
    "\n",
    "sc = SparkContext()\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "secure-chuck",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Importing the dataset for train & test from CoinDesk...\n",
    "def data_import(file = \"\"):\n",
    "    if file == \"\":\n",
    "        return None\n",
    "\n",
    "    df = spark.read.format(\"csv\").load(file, inferSchema=True, header=True)\n",
    "\n",
    "    print(\"\\n\\n\\nImported Train/Test Dataset Preview:\")\n",
    "    df.show(5)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def data_preprocessing(df, label):\n",
    "\n",
    "    ## Discarding unnecessary column 'Currency'\n",
    "    #df = df.drop('Currency')\n",
    "    \n",
    "    ## While 'Date' is not considered a feature provided it is an object,\n",
    "    ## 'Closing Price (USD)' is the label.\n",
    "    ## Thus, the rest of the columns after discarding the two would represent the feature columns\n",
    "    feature_cols = df.drop('Date', label).columns\n",
    "    \n",
    "    ## 'Date' is already formatted, thus casting to 'timestamp' without converting.\n",
    "    ## Although not a feature column, it is kept in the DataFrame for plotting the Series later.\n",
    "    df = df.withColumn('Date', df.Date.cast('timestamp'))\n",
    "\n",
    "    return df.sort('Date'), feature_cols\n",
    "\n",
    "\n",
    "## Assembling the features vector to be used by the Linear Regressor later.\n",
    "## This will add a new column called \"features\" (as named below) containing\n",
    "## the values, per row, from each nominated feature column.\n",
    "def feature_vector(feature_columns):\n",
    "    \n",
    "    assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "    assembler = assembler.transform(data)\n",
    "    \n",
    "    return assembler\n",
    "\n",
    "\n",
    "def lregresor(train, test, label):\n",
    "    \n",
    "    ## The Linear Regressor will use the newly added column \"features\" (as nominated below).\n",
    "    ## It will then make predictions based on the \"Closing Price (USD)\" labeled training set.  \n",
    "    lr = LinearRegression(featuresCol=\"features\", labelCol=label)\n",
    "    \n",
    "    ## Training on the labeled dataset...\n",
    "    model = lr.fit(train)\n",
    "    \n",
    "    ## Evaluating on the lable-free test dataset\n",
    "    evaluation = model.evaluate(test)\n",
    "    print(\"Absolute mean error: \", evaluation.meanAbsoluteError)\n",
    "    print(\"Mean squared error, root: \", evaluation.rootMeanSquaredError)\n",
    "    print(\"r2: \", evaluation.r2)\n",
    "    \n",
    "    ## Predicting on the lable-free test dataset\n",
    "    predict = model.transform(test)\n",
    "    return predict, evaluation\n",
    "\n",
    "\n",
    "## Computing a datetime object from a given date string.\n",
    "def get_timeline(str_date):\n",
    "    return datetime.strptime(str_date, \"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "## To plot the predictions and the true values, it is essential to export to CSV\n",
    "## For plotting a time Series it is also required to sort the dataset, before exporting.\n",
    "def fields_to_csv(df, fields=None, timeline=False, timeline_col=None, file=\"output\"):\n",
    "\n",
    "    if fields is None:\n",
    "        return None\n",
    "\n",
    "    sel = df.select(fields)\n",
    "\n",
    "    if timeline is True:\n",
    "        if timeline_col is None:\n",
    "            return None\n",
    "        sel = sel.sort(timeline_col, ascending=True)\n",
    "\n",
    "    sel = sel.persist()\n",
    "\n",
    "    print(\"\\n\\n\\nSaved \" + file + \"Dataset Preview:\")\n",
    "    sel.show(n=20, truncate=False)\n",
    "\n",
    "    sel.write.save(file + \".csv\", format=\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "textile-hacker",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southwest-plenty",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mathematical-glance",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "authorized-forth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Imported Train/Test Dataset Preview:\n",
      "+----------+----------+----------+----------+----------+--------+----------+\n",
      "|      Date|      Open|      High|       Low|     Close|  Volume| Adj Close|\n",
      "+----------+----------+----------+----------+----------+--------+----------+\n",
      "|2015-07-09|123.849998|124.059998|119.220001|    120.07|77821600|    120.07|\n",
      "|2015-07-08|124.480003|124.639999|122.540001|    122.57|60490200|    122.57|\n",
      "|2015-07-07|125.889999|126.150002|123.769997|125.690002|46716100|125.690002|\n",
      "|2015-07-06|124.940002|126.230003|124.849998|     126.0|27900200|     126.0|\n",
      "|2015-07-02|    126.43|126.690002|125.769997|126.440002|27122500|126.440002|\n",
      "+----------+----------+----------+----------+----------+--------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = data_import(file=\"appl_daily.csv\")\n",
    "\n",
    "label = 'Close'\n",
    "data, feature_columns = data_preprocessing(df=data, label=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "artistic-webcam",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assembled Data:\n",
      "+-------------------+---------+---------+---------+---------+---------+---------+--------------------+--------------------+\n",
      "|               Date|     Open|     High|      Low|    Close|   Volume|Adj Close|            features|                rank|\n",
      "+-------------------+---------+---------+---------+---------+---------+---------+--------------------+--------------------+\n",
      "|1980-12-12 00:00:00| 28.74984| 28.87472| 28.74984| 28.74984|117258400| 0.440188|[28.74984,28.8747...|                 0.0|\n",
      "|1980-12-15 00:00:00|27.375041|27.375041| 27.25016| 27.25016| 43971200| 0.417226|[27.375041,27.375...|1.147183664104623...|\n",
      "|1980-12-16 00:00:00| 25.37472| 25.37472| 25.24984| 25.24984| 26432000|   0.3866|[25.37472,25.3747...|2.294367328209246...|\n",
      "|1980-12-17 00:00:00|25.874799| 26.00024|25.874799|25.874799| 21610400| 0.396168|[25.874799,26.000...|3.441550992313869...|\n",
      "|1980-12-18 00:00:00|26.625201| 26.75008|26.625201|26.625201| 18362400| 0.407658|[26.625201,26.750...|4.588734656418492...|\n",
      "|1980-12-19 00:00:00|28.249759|28.375199|28.249759|28.249759| 12157600| 0.432531|[28.249759,28.375...|5.735918320523115E-4|\n",
      "|1980-12-22 00:00:00|29.625121|    29.75|29.625121|29.625121|  9340800| 0.453589|[29.625121,29.75,...|6.883101984627739E-4|\n",
      "|1980-12-23 00:00:00|30.875039|30.999918|30.875039|30.875039| 11737600| 0.472727|[30.875039,30.999...|8.030285648732362E-4|\n",
      "|1980-12-24 00:00:00| 32.50016|32.625039| 32.50016| 32.50016| 12000800| 0.497609|[32.50016,32.6250...|9.177469312836985E-4|\n",
      "|1980-12-26 00:00:00|35.500082|35.624961|35.500082|35.500082| 13893600| 0.543541|[35.500082,35.624...|0.001032465297694...|\n",
      "|1980-12-29 00:00:00| 36.00016|36.125039| 36.00016| 36.00016| 23290400| 0.551197|[36.00016,36.1250...|0.001147183664104623|\n",
      "|1980-12-30 00:00:00|35.249759|35.249759|35.124879|35.124879| 17220000| 0.537796|[35.249759,35.249...|0.001261902030515...|\n",
      "|1980-12-31 00:00:00| 34.25016| 34.25016| 34.12528| 34.12528|  8937600| 0.522491|[34.25016,34.2501...|0.001376620396925...|\n",
      "|1981-01-02 00:00:00|34.499918|34.750241|34.499918|34.499918|  5415200| 0.528227|[34.499918,34.750...| 0.00149133876333601|\n",
      "|1981-01-05 00:00:00|33.874961|33.874961|33.750082|33.750082|  8932000| 0.516747|[33.874961,33.874...|0.001606057129746...|\n",
      "|1981-01-06 00:00:00| 32.37472| 32.37472| 32.24984| 32.24984| 11289600| 0.493776|[32.37472,32.3747...|0.001720775496156...|\n",
      "|1981-01-07 00:00:00|30.999918|30.999918|30.875039|30.875039| 13921600| 0.472727|[30.999918,30.999...|0.001835493862567397|\n",
      "|1981-01-08 00:00:00|30.374961|30.374961|30.250082|30.250082|  9956800| 0.463158|[30.374961,30.374...|0.001950212228977...|\n",
      "|1981-01-09 00:00:00|31.875199|32.000082|31.875199|31.875199|  5376000|  0.48804|[31.875199,32.000...|0.002064930595388...|\n",
      "|1981-01-12 00:00:00|31.875199|31.875199|31.624879|31.624879|  5924800| 0.484208|[31.875199,31.875...|0.002179648961798784|\n",
      "+-------------------+---------+---------+---------+---------+---------+---------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Train Split:\n",
      "+-------------------+---------+---------+---------+---------+---------+---------+--------------------+\n",
      "|               Date|     Open|     High|      Low|    Close|   Volume|Adj Close|            features|\n",
      "+-------------------+---------+---------+---------+---------+---------+---------+--------------------+\n",
      "|1980-12-12 00:00:00| 28.74984| 28.87472| 28.74984| 28.74984|117258400| 0.440188|[28.74984,28.8747...|\n",
      "|1980-12-15 00:00:00|27.375041|27.375041| 27.25016| 27.25016| 43971200| 0.417226|[27.375041,27.375...|\n",
      "|1980-12-16 00:00:00| 25.37472| 25.37472| 25.24984| 25.24984| 26432000|   0.3866|[25.37472,25.3747...|\n",
      "|1980-12-17 00:00:00|25.874799| 26.00024|25.874799|25.874799| 21610400| 0.396168|[25.874799,26.000...|\n",
      "|1980-12-18 00:00:00|26.625201| 26.75008|26.625201|26.625201| 18362400| 0.407658|[26.625201,26.750...|\n",
      "|1980-12-19 00:00:00|28.249759|28.375199|28.249759|28.249759| 12157600| 0.432531|[28.249759,28.375...|\n",
      "|1980-12-22 00:00:00|29.625121|    29.75|29.625121|29.625121|  9340800| 0.453589|[29.625121,29.75,...|\n",
      "|1980-12-23 00:00:00|30.875039|30.999918|30.875039|30.875039| 11737600| 0.472727|[30.875039,30.999...|\n",
      "|1980-12-24 00:00:00| 32.50016|32.625039| 32.50016| 32.50016| 12000800| 0.497609|[32.50016,32.6250...|\n",
      "|1980-12-26 00:00:00|35.500082|35.624961|35.500082|35.500082| 13893600| 0.543541|[35.500082,35.624...|\n",
      "|1980-12-29 00:00:00| 36.00016|36.125039| 36.00016| 36.00016| 23290400| 0.551197|[36.00016,36.1250...|\n",
      "|1980-12-30 00:00:00|35.249759|35.249759|35.124879|35.124879| 17220000| 0.537796|[35.249759,35.249...|\n",
      "|1980-12-31 00:00:00| 34.25016| 34.25016| 34.12528| 34.12528|  8937600| 0.522491|[34.25016,34.2501...|\n",
      "|1981-01-02 00:00:00|34.499918|34.750241|34.499918|34.499918|  5415200| 0.528227|[34.499918,34.750...|\n",
      "|1981-01-05 00:00:00|33.874961|33.874961|33.750082|33.750082|  8932000| 0.516747|[33.874961,33.874...|\n",
      "|1981-01-06 00:00:00| 32.37472| 32.37472| 32.24984| 32.24984| 11289600| 0.493776|[32.37472,32.3747...|\n",
      "|1981-01-07 00:00:00|30.999918|30.999918|30.875039|30.875039| 13921600| 0.472727|[30.999918,30.999...|\n",
      "|1981-01-08 00:00:00|30.374961|30.374961|30.250082|30.250082|  9956800| 0.463158|[30.374961,30.374...|\n",
      "|1981-01-09 00:00:00|31.875199|32.000082|31.875199|31.875199|  5376000|  0.48804|[31.875199,32.000...|\n",
      "|1981-01-12 00:00:00|31.875199|31.875199|31.624879|31.624879|  5924800| 0.484208|[31.875199,31.875...|\n",
      "+-------------------+---------+---------+---------+---------+---------+---------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Test Split:\n",
      "+-------------------+----------+----------+----------+----------+---------+---------+--------------------+\n",
      "|               Date|      Open|      High|       Low|     Close|   Volume|Adj Close|            features|\n",
      "+-------------------+----------+----------+----------+----------+---------+---------+--------------------+\n",
      "|2008-08-05 00:00:00|155.420019|160.800009|154.819979|160.639992|172092900|21.556347|[155.420019,160.8...|\n",
      "|2008-08-06 00:00:00|159.970016|167.400026|158.000011|164.189966|197852200| 22.03272|[159.970016,167.4...|\n",
      "|2008-08-07 00:00:00|162.710026|166.149971|161.500011|163.569979|168093100|21.949523|[162.710026,166.1...|\n",
      "|2008-08-08 00:00:00|163.859985|169.649971|163.750023|169.550009|178499300|22.751986|[163.859985,169.6...|\n",
      "|2008-08-11 00:00:00|170.069967|176.500034|169.669985|173.560034|222826100|23.290093|[170.069967,176.5...|\n",
      "|2008-08-12 00:00:00|173.519993|179.290018|173.509979|176.729986|209069700| 23.71547|[173.519993,179.2...|\n",
      "|2008-08-13 00:00:00|177.979975|180.000034|175.899994|179.300032|210586600|24.060346|[177.979975,180.0...|\n",
      "|2008-08-14 00:00:00|178.329969|180.449991|177.839972|179.319979|177825200|24.063022|[178.329969,180.4...|\n",
      "|2008-08-15 00:00:00|179.039986|179.749989|175.049974|175.739964|177062900|23.582619|[179.039986,179.7...|\n",
      "|2008-08-18 00:00:00|175.570013|177.810011|173.820013|175.389969|138003600|23.535653|[175.570013,177.8...|\n",
      "|2008-08-19 00:00:00| 174.54003|177.069967|171.810034|173.530006|154051100|23.286064|[174.54003,177.06...|\n",
      "|2008-08-20 00:00:00|174.769981|176.939978|173.610008|175.840006|126737800|23.596043|[174.769981,176.9...|\n",
      "|2008-08-21 00:00:00|174.470028|175.450024|171.889969|174.289984|134936200|23.388045|[174.470028,175.4...|\n",
      "|2008-08-22 00:00:00|175.819979|177.499977|175.570013|176.789974|109902800| 23.72352|[175.819979,177.4...|\n",
      "|2008-08-25 00:00:00|176.150026|176.229975|171.660017|172.549997|121106300|23.154556|[176.150026,176.2...|\n",
      "|2008-08-26 00:00:00|172.760002|174.880024|172.609985|173.639969|111387500|23.300819|[172.760002,174.8...|\n",
      "|2008-08-27 00:00:00|173.309988|175.759991|172.189989|174.670019|119445200|23.439042|[173.309988,175.7...|\n",
      "|2008-08-28 00:00:00|175.280006|176.249989|172.749989|173.739998|107846200|23.314242|[175.280006,176.2...|\n",
      "|2008-08-29 00:00:00|172.959993|173.499966|169.039984|169.529995|149822400|  22.7493|[172.959993,173.4...|\n",
      "|2008-09-02 00:00:00|172.399994|173.499966|165.000011|166.190012|195190800|22.301107|[172.399994,173.4...|\n",
      "+-------------------+----------+----------+----------+----------+---------+---------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Absolute mean error:  1.856793905032851\n",
      "Mean squared error, root:  2.497507108002166\n",
      "r2:  0.9998054777525326\n",
      "Predicted values: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------+----------+----------+----------+---------+---------+--------------------+------------------+\n",
      "|               Date|      Open|      High|       Low|     Close|   Volume|Adj Close|            features|        prediction|\n",
      "+-------------------+----------+----------+----------+----------+---------+---------+--------------------+------------------+\n",
      "|2008-08-05 00:00:00|155.420019|160.800009|154.819979|160.639992|172092900|21.556347|[155.420019,160.8...| 159.6243652067771|\n",
      "|2008-08-06 00:00:00|159.970016|167.400026|158.000011|164.189966|197852200| 22.03272|[159.970016,167.4...|164.89001969102202|\n",
      "|2008-08-07 00:00:00|162.710026|166.149971|161.500011|163.569979|168093100|21.949523|[162.710026,166.1...|164.78768248091257|\n",
      "|2008-08-08 00:00:00|163.859985|169.649971|163.750023|169.550009|178499300|22.751986|[163.859985,169.6...|168.78474209846112|\n",
      "|2008-08-11 00:00:00|170.069967|176.500034|169.669985|173.560034|222826100|23.290093|[170.069967,176.5...|175.31209902462473|\n",
      "+-------------------+----------+----------+----------+----------+---------+---------+--------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "[('Date', 'timestamp'), ('Open', 'double'), ('High', 'double'), ('Low', 'double'), ('Close', 'double'), ('Volume', 'int'), ('Adj Close', 'double'), ('features', 'vector'), ('prediction', 'double')]\n"
     ]
    }
   ],
   "source": [
    "assembled_data = feature_vector(feature_columns=feature_columns)\n",
    "\n",
    "## The train/test-split\n",
    "\n",
    "from pyspark.sql.functions import percent_rank\n",
    "from pyspark.sql import Window\n",
    "\n",
    "assembled_data = assembled_data.withColumn(\"rank\", percent_rank().over(Window.partitionBy().orderBy(\"Date\")))\n",
    "print(\"Assembled Data:\")\n",
    "assembled_data.show()\n",
    "\n",
    "train_df = assembled_data.where(\"rank <= .8\").drop(\"rank\")\n",
    "print(\"Train Split:\")\n",
    "train_df.show()\n",
    "\n",
    "test_df = assembled_data.where(\"rank > .8\").drop(\"rank\")\n",
    "print(\"Test Split:\")\n",
    "test_df.show()\n",
    "\n",
    "predictions, _ = lregresor(train=train_df, test=test_df, label=label)\n",
    "\n",
    "## Because the Linear Regressor creates (which it returns) a new (\"predict\") DataFrame,\n",
    "## the 'Date' column dtype is changed to bigint, which requires to be casted back\n",
    "## to 'timestamp' for conversion and format.\n",
    "predictions = predictions.withColumn('Date', predictions.Date.cast('timestamp'))\n",
    "\n",
    "print(\"Predicted values: \")\n",
    "predictions.show(5)\n",
    "\n",
    "## Displaying the final dtypes to ensure the 'Date' is casted back to 'timestamp'\n",
    "print(predictions.dtypes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
